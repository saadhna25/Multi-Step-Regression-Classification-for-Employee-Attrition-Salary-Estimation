# -*- coding: utf-8 -*-
"""G_AI012_AI_107_AI130_ECM017_CSE194.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZSbR1oXGDPvYkwSkGL2X8XgGWojsU7kB

PART : 1 Attrition Prediction (Classification)
"""

from google.colab import files
uploaded = files.upload()
print(uploaded)

import pandas as pd

df = pd.read_csv('hr_project.csv')

pd.set_option('display.max_columns',None)
pd.set_option('display.max_rows',None)

df.head(5)

df['Age'].head(6)

df.describe

df.shape

df.isnull().sum().sort_values(ascending=False)

df.info

df['WorkLifeBalance'].value_counts()
df['YearsAtCompany'].value_counts()

missing_rows = df[df.isnull().any(axis=1)]
print("Number of rows with missing values:", len(missing_rows))
missing_rows.head()

to_drop = [
    'EmployeeNumber',
    'EmployeeCount',
    'Over18',
    'StandardHours'
]

existing_columns = df.columns
columns_to_drop = [col for col in to_drop if col in existing_columns]

df = df.drop(columns=columns_to_drop)
display(df.head(5))

import pandas as pd
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('hr_project.csv')

df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})

le = LabelEncoder()
for col in df.select_dtypes(include='object').columns:
    df[col] = le.fit_transform(df[col])

print(df.head())

from sklearn.model_selection import train_test_split

X = df.drop('Attrition', axis=1)
y = df['Attrition']

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.25,
    random_state=42,
    stratify=y
)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

pipe_lr = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42))
])

pipe_lr.fit(X_train, y_train)

y_prob_lr = pipe_lr.predict_proba(X_test)[:, 1]

import numpy as np
y_custom_pred = (y_prob_lr > 0.3).astype(int)

print("Custom Threshold Predictions:", y_custom_pred[:5])

print("Target distribution:\n", y_train.value_counts(normalize=True))

y_pred_lr = pipe_lr.predict(X_test)
y_prob_lr = pipe_lr.predict_proba(X_test)[:, 1]

from sklearn.metrics import classification_report, confusion_matrix

print("Classification Report:\n", classification_report(y_test, y_pred_lr))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_lr))

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix

model_dt = DecisionTreeClassifier(max_depth=5, class_weight='balanced', random_state=42)

model_dt.fit(X_train, y_train)

y_pred_dt = model_dt.predict(X_test)

y_prob_dt = model_dt.predict_proba(X_test)[:, 1]

print("Decision Tree Predictions:", y_pred_dt[:5])
print("Decision Tree Probabilities:", y_prob_dt[:5])

print("Classification Report:\n", classification_report(y_test, y_pred_dt))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))

import numpy as np

y_custom_pred_dt = (y_prob_dt > 0.3).astype(int)

print("Custom Threshold Report:\n", classification_report(y_test, y_custom_pred_dt))
print("Custom Threshold Confusion Matrix:\n", confusion_matrix(y_test, y_custom_pred_dt))

from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

pipe_svm = Pipeline([
    ('scaler', StandardScaler()),
    ('svm', SVC(probability=True,
                kernel='rbf',
                class_weight='balanced',
                C=1.0,
                random_state=42))
])

pipe_svm.fit(X_train, y_train)

y_pred_svm = pipe_svm.predict(X_test)

y_prob_svm = pipe_svm.predict_proba(X_test)[:, 1]

print("SVM Predictions:", y_pred_svm[:5])
print("SVM Probabilities:", y_prob_svm[:5])

y_custom_pred_svm = (y_prob_svm > 0.3).astype(int)

from sklearn.metrics import classification_report, confusion_matrix
print("Custom Threshold Report:\n", classification_report(y_test, y_custom_pred_svm))
print("Custom Threshold Confusion Matrix:\n", confusion_matrix(y_test, y_custom_pred_svm))

print("Default Threshold Report:\n", classification_report(y_test, y_pred_svm))

from sklearn.metrics import roc_auc_score

print("LogReg AUC-ROC:", roc_auc_score(y_test, y_prob_lr))
print("Tree AUC-ROC:", roc_auc_score(y_test, y_prob_dt))
print("SVM AUC-ROC:", roc_auc_score(y_test, y_prob_svm))

from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

fpr, tpr, _ = roc_curve(y_test, y_prob_lr)
plt.plot(fpr, tpr, label="LogReg")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.show()

from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)

fpr_dt, tpr_dt, _ = roc_curve(y_test, y_prob_dt)

fpr_svm, tpr_svm, _ = roc_curve(y_test, y_prob_svm)

plt.plot(fpr_lr, tpr_lr, label="Logistic Regression")
plt.plot(fpr_dt, tpr_dt, label="Decision Tree")
plt.plot(fpr_svm, tpr_svm, label="SVM")
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')

plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves – Attrition Prediction")
plt.legend()
plt.grid()
plt.show()

"""**PART : 2 Simulating Future Salaries (Data Augmentation)**


"""

import pandas as pd

df = pd.DataFrame({
    'EmployeeID': [101, 102, 103, 104],
    'MonthlyIncome': [3000, 4500, 5500, 4000]
})
df["FutureSalary"] = df["MonthlyIncome"] * 1.08
df

df['FutureSalary'] = df['MonthlyIncome'] * 1.08
df

import pandas as pd

df_hr = pd.read_csv('hr_project.csv')

print(df_hr.columns)

df_hr['Increment'] = df_hr['PerformanceRating'].apply(lambda x: 1.10 if x == 4 else 1.05)

df_hr['FutureSalary'] = df_hr['MonthlyIncome'] * df_hr['Increment']

print(df_hr[['EmployeeNumber',
             'MonthlyIncome',
             'PerformanceRating',
             'Increment',
             'FutureSalary']].head())

df_hr = df.copy()

print("Min FutureSalary:", df_hr['FutureSalary'].min())
print("Max FutureSalary:", df_hr['FutureSalary'].max())

"""**PART 3: Salary Prediction (Regression)**"""

y_prob_train = pipe_svm.predict_proba(X_train)[:, 1]
p_stay_train = 1 - y_prob_train

stayers_train = p_stay_train > 0.6

print("P_leave:", y_prob_train)
print("P_stay:", p_stay_train)
print("Stayers mask:", stayers_train)

X_reg_train = X_train[stayers_train]

y_reg_train = df_hr.loc[X_reg_train.index, 'FutureSalary']

print("X_reg_train shape:", X_reg_train.shape)
print("y_reg_train shape:", y_reg_train.shape)
print("Sample rows:")
print(y_reg_train.head())

from sklearn.model_selection import train_test_split

X_rt, X_re, y_rt, y_re = train_test_split(
    X_reg_train, y_reg_train,
    test_size=0.25, random_state=42
)

print("X_rt shape:", X_rt.shape)
print("y_rt shape:", y_rt.shape)
print("X_re shape:", X_re.shape)
print("y_re shape:", y_re.shape)

from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.svm import SVR
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import pandas as pd

models = {
    'RandomForest': RandomForestRegressor(random_state=42),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'SVR': SVR()
}

results = {}

for name, model in models.items():
    pipe = Pipeline([
        ('scale', StandardScaler()),
        ('reg', model)
    ])

    pipe.fit(X_rt, y_rt)


    y_pred = pipe.predict(X_re)


    rmse = np.sqrt(mean_squared_error(y_re, y_pred))
    r2 = r2_score(y_re, y_pred)


    mape = (abs((y_re - y_pred) / y_re).mean()) * 100


    results[name] = {
        'RMSE': rmse,
        'R2': r2,
        'MAPE': mape
    }

pd.DataFrame(results).T

"""About the above output

RMSE: lower = better

R²: closer to 1 = better fit

MAPE (optional): lower % = better accuracy

**PART 4: Identifying “Likely to Stay” Employees**
"""

y_prob_train = pipe_svm.predict_proba(X_train)[:, 1]

print("P_leave:", y_prob_train)

p_stay_train = 1 - y_prob_train

print("P_stay :", p_stay_train)

stayers_train = p_stay_train > 0.6

print("Likely Stayers Mask :", stayers_train)
print("Total number of likely stayers in train:", stayers_train.sum())

X_train_stayers = X_train[stayers_train]

print("Features of likely stayers:")
print(X_train_stayers.head(5))

y_train_stayers = df_hr.loc[X_train_stayers.index, "FutureSalary"]

print("Step 5 - FutureSalary of likely stayers:")
print(y_train_stayers.head(5))

"""**PART 5: Estimate Expected Salary Loss (Combined Metric)**"""

y_prob_all = pipe_svm.predict_proba(X)[:, 1]

print("P_leave for employees:", y_prob_all)

future_salary_all = df_hr["FutureSalary"].values

print("FutureSalary for employees:", future_salary_all)

expected_loss = y_prob_all * future_salary_all

print("Expected loss for employees:", expected_loss)

total_expected_loss = expected_loss.sum()

print("Total Expected Loss (₹):", round(total_expected_loss, 2))